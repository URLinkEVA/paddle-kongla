# 1.(必修题)
在第五章（上）《卷积神经网络理论解读》中，我们基于LeNet网络实现了手写体数字识别实验。在本实践中，我们重复该实验，以最初的试验结果作为基线（Baseline），运用在本章内学到的网络优化方法进行调优，尝试提升模型精度。

a) 实验baseline：给出代码，跑出baseline结果为0.895

b) 尝试修改学习率、批大小、更换优化器、增加训练轮数、增加学习率衰减、学习率预热等策略来提升模型精度。


# 2.(附加题&加分题)
在课程中我们讲到了Adam优化器及其实现方法，也了解到可以通过在损失函数中引入ℓ2正则化来缓解过拟合。但Adam优化器中自适应学习率的存在会使得ℓ2正则化失效。AdamW优化器的提出则可解决这一问题。
大家可通过阅读论文DECOUPLED WEIGHT DECAY REGULARIZATION详细了解AdamW优化器，并通过调用paddle.optimzer.AdamW API实现AdamW优化器指导LeNet网络在MNIST数据集上完成训练。


# 3.(附加题&简答题&加分题)
小明意识到了自己在搭建宠物店猫狗识别系统的过程中，在采集数据集犯下的错误。经过调整后，小明开始训练网络，发现在训练数据上损失不断下降而在验证数据上损失先降后增，请分析该现象是什么，如何缓解？
