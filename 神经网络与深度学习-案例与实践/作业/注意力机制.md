# 1
Transformer层数设置为多层，采用随机初始化位置编码，并且设置位置编码为可训练的方式，并进行文本分类实验，比较实验结果。(必修题)


# 2
训练时候加入warmup的策略，并适当调整warmup的参数，并与不加warmup的实验进行对比。(附加题&加分题)


# 3. (附加题&简答题&加分题)
小明是一位建筑设计师，在工作中经常需要手工的查询一些建筑规范条文，规范条文非常的多，每次都需要手工翻阅那些规范条文，非常的不方便。小李是一位计算机的学生，当得知小明的情况后，想用技术手段帮助小明，最开始使用基于关键词的匹配，但是对字面上相同，语义不同和字面上不一样，但语义相似的情况不好处理，于是想利用神经网络的方法来解决这个问题，小李构建了双向LSTM的网络，并在LSTM上加了点积注意力，对于一个小批次的数据不同长度的句子，加入对齐字符进行了对齐，在计算注意力机制的时候，对于一些对齐的字符也计算注意力，并分配注意力权重，最后将训练好的网络融入到规范条文匹配中，请问上述的做法有什么问题？
