# 开始构建你的优质Prompt

# 近十年深度学习模型主要跟迭

## 传统模型

以RNN、CNN为主的神经网络

## 预训练模型

Transformer网络的出现，BERT与GPT的比拼，Encoder为主的自编码结构，BERT领先一步

## 大模型

GPT3.0的出现，Decoder为主的自回归结构转折，chatgpt引领大模型（LLM，large language model）时代

1750忆神经元数量



大模型（LLMs）涌现出的三大能力：上下文学习、指令遵循、思维链推理COT



# 为什么大模型能够有如此强大的表现力

## 数据

不断追求更多的数据的训练

不断追求与人类价值观的对齐

[alignment](https://zhuanlan.zhihu.com/p/610604904)

## 算力

更高要求的基础设施（infra）

硬件、深度学习框架、模型的高效协同

## 模型

千亿以上的参数量，具有涌现能力

SFT（supervised fine-tuning）

RLHF（Reinforcement Learning from Human Feedback）

# 大模型与Prompt

prompt基本定义：驱动大模型进行表达的文本描述。

例：帮我撰写一个验证邮箱的正则表达式



## AIGC(AI Generated Content)

AIGC：新一代内容生产方式

### 从业者

高效工具

- 更精细化的内容打磨
- 更有深度的创意创作

### 企业

降本增效

- 更高效的资源分配
- 更稳定的业务发展

### 产业

代际革新

- 生产方式优化
- 促进整体效率提升
- 优化资源配置



# 如何定义优质Prompt

## 满足三点

### 表达清晰

通俗易懂，表达简洁清晰，做到不仅可以让模型生成出好的内容，普通人也能明白其中含义

案例：特殊符号等非结构化提示词不具备可读性且为来随版本迭代会失去其作用

### 通用性强

在同类任务上，更换主体词后仍有不错效果

案例：一副绘制二次元猫猫头像的提示词，更换主题词为狗狗时仍可以生成高质量头像

### 生成稳定

相同提示词情况下，多次生成的内容足够稳定

案例：有些提示词生成10次才可能有1次满足我们使用需求，不够稳定的提示词会影响工作效率

# 优质prompt生产流程

简单了解大模型生成原理

## 写出一个基础的prompt

prompt = 任务+生成主题+细节+形式

### case1

我希望你充当讲故事的人，你要想出一个童话故事

prompt = 任务+答案主体+细节+形式

### case2

我希望你充当讲故事的人，你要想出一个中华文化的童话故事，要求内容积极向上，与猫猫有关

# 如何构建优质prompt

## 简历润色

帮我扩写并优化一下简历中的这句话：balabala

## 面试准备

现在你是某厂大模型运行面试官，希望你可以给面试常问的几个问题，我的岗位是算法岗

## 歌词生成

现在你是方文山的实力粉丝，请写一组歌词，关于青山万水

## 种草文章

请用小红书文案风格，写一篇关于“某品牌口红”的种草推文，需要多用点emoji表情，活泼可爱的语气，最后加tag

## 代码生成

请帮我写一个能读取pdf的代码，需要是python形式

## 组住电脑

请给出一台总价不超过500元台式机配置单，要图吧垃圾佬的版本，接受二手配件

